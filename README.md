# tensorflow- #
学习使用tensorflow，（2018年3月5日 10:39:54）

## 神经网络优化算法 ##

### 1.梯度下降算法 ###
> 梯度算法是基于全局的损失和进行的参数跟新，每次更新需要对全部数据进行训练，更新参数后仍然需要
对全部训练数据进行训练。（可以达到局部最优，不能达到全局最优）

### 2.随机梯度下降算法 ###
> 随机梯度下降算法是：在每一轮的迭代中，随机优化某一条数据上的损失函数（可能无法达到局部最优）

### 3.学习率问题 ###
> 学习率决定了参数每次更新的幅度，如果幅度过大，可能导致参数在极优值两侧来回移动，如果过小，则收敛速度慢
####  指数衰减法： ####
   > 让模型在训练的前期快速接近较优解，又可以保证在模型训练的后期不会有太大的波动，从而更加接近局部最优。
   
    1. 衰减学习率 = 学习率*衰减率^（全局迭代步长/衰减步长）
        1. 学习率： 事先设定的初始学习率
        2. 衰减率： 衰减系数（每一个衰减步长下，学习率衰减程度。）
        3. 全局迭代步长： 已经训练数据的轮数
        4. 衰减步长：设定的每执行多少轮数据训练，进行学习率衰减   
    2. tf.train.exponential_decay(初始学习率，全局迭代步长，衰减步长，衰减率，衰减方式) ： tensorflow提供的指数衰减函数
        1. 衰减方式：staircase 布尔类型
            1. False：默认值，此时学习率的衰减成曲线衰减，（全局迭代步长/衰减步长）成线性减小
            2. true： 此时学习率成阶梯状衰减,（全局迭代步长/衰减步长）被取整，程散列减小
### 4.过拟合问题 ###
> 当一个模型过于复杂之后，它可能很好的模拟每一个训练数据中随机噪音部分而冲淡了学习训练数据中通用的行为。
> 模型在训练过程中，为了充分模拟训练数据的行为，保有了很多特征参数，又因为训练数据不足以确定所有参数合适的值，使得在实际应用中与预测
> 偏差较大，出现过拟合。

> 解决过拟合有两种方法，一是主动减少特征参数的个数，但是选择保留特征参数很复杂，不能保证减去的都是无用的特征参数，这会造成模型效果不好
> 在一个就是正则化，它会保留所有特征参数

#### 正则化 ####
> 在损失函数中加入刻画模型复杂度的指标
> 
[正则化详细解释](https://www.zhihu.com/question/20700829)