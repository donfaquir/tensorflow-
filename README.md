# tensorflow- #
学习使用tensorflow，（2018年3月5日 10:39:54）  
```
换行方法：每行末尾加两个空格
```
## 神经网络优化算法 ##

### 1.梯度下降算法 ###
> 梯度算法是基于全局的损失和进行的参数跟新，每次更新需要对全部数据进行训练，更新参数后仍然需要
对全部训练数据进行训练。（可以达到局部最优，不能达到全局最优）

### 2.随机梯度下降算法 ###
> 随机梯度下降算法是：在每一轮的迭代中，随机优化某一条数据上的损失函数（可能无法达到局部最优）

### 3.学习率问题 ###
> 学习率决定了参数每次更新的幅度，如果幅度过大，可能导致参数在极优值两侧来回移动，如果过小，则收敛速度慢
####  指数衰减法： ####
   > 让模型在训练的前期快速接近较优解，又可以保证在模型训练的后期不会有太大的波动，从而更加接近局部最优。
   
    1. 衰减学习率 = 学习率*衰减率^（全局迭代步长/衰减步长）
        1. 学习率： 事先设定的初始学习率
        2. 衰减率： 衰减系数（每一个衰减步长下，学习率衰减程度。）
        3. 全局迭代步长： 已经训练数据的轮数
        4. 衰减步长：设定的每执行多少轮数据训练，进行学习率衰减   
    2. tf.train.exponential_decay(初始学习率，全局迭代步长，衰减步长，衰减率，衰减方式) ： tensorflow提供的指数衰减函数
        1. 衰减方式：staircase 布尔类型
            1. False：默认值，此时学习率的衰减成曲线衰减，（全局迭代步长/衰减步长）成线性减小
            2. true： 此时学习率成阶梯状衰减,（全局迭代步长/衰减步长）被取整，程散列减小
### 4.过拟合问题 ###
> 当一个模型过于复杂之后，它可能很好的模拟每一个训练数据中随机噪音部分而冲淡了学习训练数据中通用的行为。
> 模型在训练过程中，为了充分模拟训练数据的行为，保有了很多特征参数，又因为训练数据不足以确定所有参数合适的值，使得在实际应用中与预测
> 偏差较大，出现过拟合。
> 训练数据集样本单一，也是导致过拟合问题的一个原因，还有训练噪声太大，也能导致过拟合问题。（来自《机器学习实践应用》李博）

？？？？特征参数是怎么生成的，特征参数的数量怎么控制的

> 解决过拟合有两种方法，一是主动减少特征参数的个数，但是选择保留特征参数很复杂，不能保证减去的都是无用的特征参数，这会造成模型效果不好
> 在一个就是正则化，它会保留所有特征参数  
> 解决过拟合三个注意：（来自《机器学习实践应用》李博

 1. 训练和建立模型的时候，一定要从简单的模型开始训练
 2. 训练数据，尽可能的覆盖全部数据类型，数据需要清洗后才能进行算法训练
 3. 通过添加惩罚函数预防过拟合 

#### 正则化 ####
[正则化详细解释](https://www.zhihu.com/question/20700829)
> 在损失函数中加入刻画模型复杂度的指标（模型复杂度：神经网络模型中所有特征参数综合的表现，可以理解为之和的大小)   
> 通过控制特征参数的大小，即是特征参数越小，其对输出结果的影响越小，如果无限接近于零，那么这个特征参数就不再影响输出结果，
> *** 
> 函数：J(θ)+λR(W)  
> J(θ): 代表损失函数  
> λ ：  代表模型复杂损失在总损失的比例，即是每次优化，模型复杂度被优化的比例  
> R(W)：模型的复杂程度，w为神经网络上的所有参数，包括权重w和偏置项b   
> L1正则化： R(w)=‖W‖₁ = Σ｜W｜  
> L2正则换： R(w)=‖W‖² = Σ｜W²｜  
